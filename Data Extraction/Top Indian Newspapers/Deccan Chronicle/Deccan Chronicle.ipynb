{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alcholic Anonymous News articles extraction from Deccan Chronicle. Data Extraction of following parameters\n",
    "- Headline\n",
    "- Description\n",
    "- Author\n",
    "- Published_Date\n",
    "- News\n",
    "- URL\n",
    "- Keywords\n",
    "- Summary\n",
    "\n",
    "### Importing the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options # enables options in web browser\n",
    "from selenium import webdriver # web-based automation tool for Python\n",
    "from newspaper import Article # Article scraping & curation\n",
    "from bs4 import BeautifulSoup # Python library for pulling data out of HTML and XML files\n",
    "from requests import get # standard for making HTTP requests in Python\n",
    "import pandas as pd # library written for data manipulation and analysis\n",
    "import sys, time #  System-specific parameters and functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Empty lists for Alcholic Anonymous News Articles parameters data to be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines, descriptions, dates, authors, news, keywords, summaries, urls = [], [], [], [], [], [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the total no.of.pages by total no.of articles from google search resultsÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'Alcoholics Anonymous site:www.deccanchronicle.com'\n",
    "\n",
    "url = 'https://www.google.com/search?q=' + '+'.join(keyword.split())\n",
    "\n",
    "soup = BeautifulSoup(get(url).text, 'lxml')\n",
    "try:\n",
    "    # Extracts the digits if it the resulted number without comma ','. eg: About 680 results (0.23 seconds)\n",
    "    max_pages = round([int(s) for s in soup.select_one('div#resultStats').text.split() if s.isdigit()][0]/10)\n",
    "    max_pages = max_pages + 1\n",
    "except:\n",
    "    # Extracts the digits if it the resulted number without comma ','. eg: About 1,080 results (0.23 seconds)\n",
    "    max_pages = round(int(''.join(i for i in soup.select_one('div#resultStats').text if i.isdigit()))/10)\n",
    "    max_pages = max_pages + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterates max_pages value through while loop. Scraping the Articles urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 : 3\r"
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "options.headless = True\n",
    "browser = webdriver.Chrome(options=options)\n",
    "browser.get(url)\n",
    "\n",
    "index = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        index +=1\n",
    "        page = browser.page_source\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "        linky = [soup.select('.r')[i].a['href'] for i in range(len(soup.select('.r')))]\n",
    "        urls.extend(linky)\n",
    "        if index == max_pages:\n",
    "            break\n",
    "        browser.find_element_by_xpath('//*[@id=\"pnnext\"]/span[2]').click()\n",
    "        time.sleep(2)\n",
    "        sys.stdout.write('\\r' + str(index) + ' : ' + str(max_pages) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To remove duplicates urls entries in the list by executing below line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "urls = list(dict.fromkeys(urls))\n",
    "print(len(urls), type(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterates urls through for loop. Scraping the Articles using BeautifulSoup4 which extracts above parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0 : https://www.deccanchronicle.com/content/tags/alcoholics-anonymous\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py:1204: UnknownTimezoneWarning: tzname IST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  category=UnknownTimezoneWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 59sccanchronicle.com/nation/current-affairs/240817/ram-rahim-singh-confirms-hell-appear-in-court-for-verdict-tomorrow.html9\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, url in enumerate(urls):\n",
    "    try:\n",
    "        # Parse the url to NewsPlease \n",
    "        soup = BeautifulSoup(get(url).text, 'lxml')\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        article.nlp()\n",
    "        \n",
    "        # Extracts the Headlines\n",
    "        try:\n",
    "            try:\n",
    "                headlines.append(article.title.strip())\n",
    "            except:\n",
    "                headlines.append(soup.select_one('meta[property=\"og:title\"]')['content'].strip())\n",
    "        except:\n",
    "            headlines.append(None)\n",
    "            \n",
    "        # Extracts the Descriptions    \n",
    "        try:\n",
    "            try:\n",
    "                descriptions.append(soup.select_one('meta[property=\"og:description\"]')['content'].strip().replace('\\n', ' '))\n",
    "            except:\n",
    "                descriptions.append(article.meta_description.strip())\n",
    "        except:\n",
    "            descriptions.append(None)\n",
    "            \n",
    "        # Extracts the Authors\n",
    "        try:\n",
    "            try:\n",
    "                authors.append(soup.select_one('meta[name=\"author\"]')['content'].strip())\n",
    "            except:\n",
    "                authors.append(article.authors.strip())\n",
    "        except:\n",
    "            authors.append(None)\n",
    "        \n",
    "        # Extracts the published dates\n",
    "        try:\n",
    "            try:\n",
    "                dates.append(soup.select_one('meta[property=\"article:published_time\"]')['content'].strip())\n",
    "            except:\n",
    "                dates.append(str(article.publish_date))\n",
    "        except:\n",
    "            dates.append(None)\n",
    "            \n",
    "        # Extracts the news articles\n",
    "        try:\n",
    "            try:\n",
    "                news.append(soup.select_one('.storyText').text.replace('\\n', '').strip())\n",
    "            except:\n",
    "                news.append(article.text.strip())\n",
    "        except:\n",
    "            news.append(None)\n",
    "            \n",
    "        # Extracts Keywords and Summaries    \n",
    "        try:\n",
    "            keywords.append(article.keywords)\n",
    "            summaries.append(article.summary)\n",
    "        except:\n",
    "            keywords.append(None)\n",
    "            summaries.append(None)\n",
    "            \n",
    "    except:\n",
    "        headlines.append(None)\n",
    "        descriptions.append(None)\n",
    "        authors.append(None)\n",
    "        dates.append(None)\n",
    "        news.append(None)\n",
    "        keywords.append(None)\n",
    "        summaries.append(None)\n",
    "\n",
    "    sys.stdout.write('\\r' + str(index) + ' : ' + str(url) + '\\r')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Array Length of each list to create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29 29 29 29 29 29 29\n"
     ]
    }
   ],
   "source": [
    "print(len(headlines), len(descriptions), len(authors), len(dates), len(news), len(keywords), len(summaries), len(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a csv file after checking array length and droping the missing values from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published_Dates</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alcoholics Anonymous</td>\n",
       "      <td>Alcoholics Anonymous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Alcoholics Anonymous: The helping hand for add...</td>\n",
       "      <td>[alcoholics, men, share, ngo, group, fellowshi...</td>\n",
       "      <td>Alcoholics Anonymous: The helping hand for add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alcoholics Anonymous: The helping hand for add...</td>\n",
       "      <td>This group is not a rehabilitation centre or a...</td>\n",
       "      <td>None</td>\n",
       "      <td>May 3, 2016, 3:24 am IST</td>\n",
       "      <td>What begins as social drinking turns into alco...</td>\n",
       "      <td>[alcoholics, addicts, alcoholic, group, alcoho...</td>\n",
       "      <td>What begins as social drinking turns into alco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We are addicted to the absence of absence, say...</td>\n",
       "      <td>Actor-director Pooja Bhatt talks about dealing...</td>\n",
       "      <td>None</td>\n",
       "      <td>Apr 1, 2017, 12:23 am IST</td>\n",
       "      <td>Power, determination and the unabashed guts to...</td>\n",
       "      <td>[bhatt, things, pooja, day, life, addicted, ch...</td>\n",
       "      <td>Power, determination and the unabashed guts to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Helping alcoholics kick the bottle!</td>\n",
       "      <td>Today Harsha is a happily married man and he c...</td>\n",
       "      <td>None</td>\n",
       "      <td>Aug 28, 2017, 1:23 am IST</td>\n",
       "      <td>BENGALURU: Despite measures being taken by sev...</td>\n",
       "      <td>[alcoholics, volunteers, members, alcoholic, a...</td>\n",
       "      <td>BENGALURU: Despite measures being taken by sev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA reaches out to schools now, rural men in TN...</td>\n",
       "      <td>Consumption of alcohol is also high in Tamil N...</td>\n",
       "      <td>None</td>\n",
       "      <td>Aug 1, 2018, 6:15 am IST</td>\n",
       "      <td>Thanjavur: It will be startling to note that t...</td>\n",
       "      <td>[drinking, men, alcohol, consume, urban, reach...</td>\n",
       "      <td>53.9 per cent of men and 8.8 per cent of women...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Headlines  \\\n",
       "0                               Alcoholics Anonymous   \n",
       "1  Alcoholics Anonymous: The helping hand for add...   \n",
       "2  We are addicted to the absence of absence, say...   \n",
       "3                Helping alcoholics kick the bottle!   \n",
       "4  AA reaches out to schools now, rural men in TN...   \n",
       "\n",
       "                                        Descriptions Authors  \\\n",
       "0                               Alcoholics Anonymous    None   \n",
       "1  This group is not a rehabilitation centre or a...    None   \n",
       "2  Actor-director Pooja Bhatt talks about dealing...    None   \n",
       "3  Today Harsha is a happily married man and he c...    None   \n",
       "4  Consumption of alcohol is also high in Tamil N...    None   \n",
       "\n",
       "             Published_Dates  \\\n",
       "0                       None   \n",
       "1   May 3, 2016, 3:24 am IST   \n",
       "2  Apr 1, 2017, 12:23 am IST   \n",
       "3  Aug 28, 2017, 1:23 am IST   \n",
       "4   Aug 1, 2018, 6:15 am IST   \n",
       "\n",
       "                                            Articles  \\\n",
       "0  Alcoholics Anonymous: The helping hand for add...   \n",
       "1  What begins as social drinking turns into alco...   \n",
       "2  Power, determination and the unabashed guts to...   \n",
       "3  BENGALURU: Despite measures being taken by sev...   \n",
       "4  Thanjavur: It will be startling to note that t...   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  [alcoholics, men, share, ngo, group, fellowshi...   \n",
       "1  [alcoholics, addicts, alcoholic, group, alcoho...   \n",
       "2  [bhatt, things, pooja, day, life, addicted, ch...   \n",
       "3  [alcoholics, volunteers, members, alcoholic, a...   \n",
       "4  [drinking, men, alcohol, consume, urban, reach...   \n",
       "\n",
       "                                           Summaries  \n",
       "0  Alcoholics Anonymous: The helping hand for add...  \n",
       "1  What begins as social drinking turns into alco...  \n",
       "2  Power, determination and the unabashed guts to...  \n",
       "3  BENGALURU: Despite measures being taken by sev...  \n",
       "4  53.9 per cent of men and 8.8 per cent of women...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl = pd.DataFrame({'Headlines' : headlines,\n",
    "                    'Descriptions' : descriptions,\n",
    "                    'Authors' : authors,\n",
    "                    'Published_Dates' : dates, \n",
    "                    'Articles' : news,\n",
    "                    'Keywords' : keywords,\n",
    "                    'Summaries' : summaries,})\n",
    "\n",
    "tbl.dropna()\n",
    "tbl.to_csv('Deccan_Chronicle.csv', index=False)\n",
    "tbl.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
