{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alcholic Anonymous News articles extraction from The Economic Times. Data Extraction of following parameters\n",
    "- Headline\n",
    "- Description\n",
    "- Author\n",
    "- Published_Date\n",
    "- News\n",
    "- URL\n",
    "- Keywords\n",
    "- Summary\n",
    "\n",
    "### Importing the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options # enables options in web browser\n",
    "from selenium import webdriver # web-based automation tool for Python\n",
    "from newspaper import Article # Article scraping & curation\n",
    "from bs4 import BeautifulSoup # Python library for pulling data out of HTML and XML files\n",
    "from requests import get # standard for making HTTP requests in Python\n",
    "import pandas as pd # library written for data manipulation and analysis\n",
    "import sys, time #  System-specific parameters and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Empty lists for Alcholic Anonymous News Articles parameters data to be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines, descriptions, dates, authors, news, keywords, summaries, urls = [], [], [], [], [], [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the total no.of.pages by total no.of articles from google search resultsÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'Alcoholics Anonymous site:economictimes.indiatimes.com'\n",
    "\n",
    "url = 'https://www.google.com/search?q=' + '+'.join(keyword.split())\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "browser = webdriver.Chrome(options=options)\n",
    "browser.get(url)\n",
    "\n",
    "page = browser.page_source\n",
    "soup = BeautifulSoup(page, 'lxml')\n",
    "max_pages = round([int(s) for s in soup.select_one('#resultStats').text.split() if s.isdigit()][0]/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterates max_pages value through while loop. Scraping the Articles urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 : 9\r"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        index +=1\n",
    "        page = browser.page_source\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "        linky = [soup.select('.r')[i].a['href'] for i in range(len(soup.select('.r')))]\n",
    "        urls.extend(linky)\n",
    "        if index == max_pages:\n",
    "            break\n",
    "        browser.find_element_by_xpath('//*[@id=\"pnnext\"]/span[2]').click()\n",
    "        time.sleep(2)\n",
    "        sys.stdout.write('\\r' + str(index) + ' : ' + str(max_pages) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To remove duplicates urls entries in the list by executing below line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "urls = list(dict.fromkeys(urls))\n",
    "print(len(urls), type(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterates urls through for loop. Scraping the Articles with above parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 29sictimes.indiatimes.com/etstatic/sitemaps/et/2017-February-1.xmlhcare-to-add-another-3000-beds-by-2017/47703955450335up/articleshow/66150706.cmsicleshow/msid-17904247,curpg-3.cms?from=mdr7646f2232584cee6455ead37\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, url in enumerate(urls):\n",
    "    try:\n",
    "        # Parse the url to NewsPlease \n",
    "        soup = BeautifulSoup(get(url).text, 'lxml')\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        article.nlp()\n",
    "        \n",
    "        # Extracts the Headlines\n",
    "        try:\n",
    "            try:\n",
    "                headlines.append(article.title.strip())\n",
    "            except:\n",
    "                headlines.append(soup.select_one('meta[property=\"og:title\"]')['content'].strip())\n",
    "        except:\n",
    "            headlines.append(None)\n",
    "            \n",
    "        # Extracts the Descriptions    \n",
    "        try:\n",
    "            try:\n",
    "                descriptions.append(soup.select_one('meta[property=\"og:description\"]')['content'].strip().replace('\\n', ' '))\n",
    "            except:\n",
    "                descriptions.append(article.meta_description.strip())\n",
    "        except:\n",
    "            descriptions.append(None)\n",
    "            \n",
    "        # Extracts the Authors\n",
    "        try:\n",
    "            try:\n",
    "                authors.append(soup.select_one('meta[name=\"author\"]')['content'].strip())\n",
    "            except:\n",
    "                authors.append(article.authors.strip())\n",
    "        except:\n",
    "            authors.append(None)\n",
    "        \n",
    "        # Extracts the published dates\n",
    "        try:\n",
    "            try:\n",
    "                dates.append(soup.select_one('meta[property=\"article:published_time\"]')['content'].strip())\n",
    "            except:\n",
    "                dates.append(str(article.publish_date))\n",
    "        except:\n",
    "            dates.append(None)\n",
    "            \n",
    "        # Extracts the news articles\n",
    "        try:\n",
    "            try:\n",
    "                news.append(soup.select_one('.storyText').text.replace('\\n', '').strip())\n",
    "            except:\n",
    "                news.append(article.text.strip())\n",
    "        except:\n",
    "            news.append(None)\n",
    "            \n",
    "        # Extracts Keywords and Summaries    \n",
    "        try:\n",
    "            keywords.append(article.keywords)\n",
    "            summaries.append(article.summary)\n",
    "        except:\n",
    "            keywords.append(None)\n",
    "            summaries.append(None)\n",
    "            \n",
    "    except:\n",
    "        headlines.append(None)\n",
    "        descriptions.append(None)\n",
    "        authors.append(None)\n",
    "        dates.append(None)\n",
    "        news.append(None)\n",
    "        keywords.append(None)\n",
    "        summaries.append(None)\n",
    "\n",
    "    sys.stdout.write('\\r' + str(index) + ' : ' + str(url) + '\\r')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Array Length of each list to create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 59 59 59 59 59 59 59\n"
     ]
    }
   ],
   "source": [
    "print(len(headlines), len(descriptions), len(authors), len(dates), len(news), len(keywords), len(summaries), len(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a csv file after checking array length and droping the missing values from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published_Dates</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alcoholics Anonymous News and Updates from The...</td>\n",
       "      <td>Alcoholics Anonymous News and Updates from The...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Food ministry seeks delay in ethanol blending ...</td>\n",
       "      <td>[mills, food, ministry, business, economic, re...</td>\n",
       "      <td>Food ministry seeks delay in ethanol blending ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inner Power</td>\n",
       "      <td>The agnostics say they cant suddenly start bel...</td>\n",
       "      <td>None</td>\n",
       "      <td>2014-06-17T05:50:00.000Z</td>\n",
       "      <td>In a head-to-head evaluation of the Alcoholics...</td>\n",
       "      <td>[power, say, step, aa, believe, alcoholics, be...</td>\n",
       "      <td>In a head-to-head evaluation of the Alcoholics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Living to see another day</td>\n",
       "      <td>What's so great about living for the day? Or f...</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-07-23T06:14:00.000Z</td>\n",
       "      <td>What's so great about living for the day? Or f...</td>\n",
       "      <td>[means, passes, live, moment, day, tomorrow, l...</td>\n",
       "      <td>What's so great about living for the day?\\nThe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can NREGS become more effective if treated as ...</td>\n",
       "      <td>A school of thought has emerged that believes ...</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-04-05T11:34:00.000Z</td>\n",
       "      <td>Can Alcoholics Anonymous (AA) be turned into a...</td>\n",
       "      <td>[maximise, nregs, effective, business, yunus, ...</td>\n",
       "      <td>Can Alcoholics Anonymous (AA) be turned into a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A simple case of sorry and thanks</td>\n",
       "      <td>Alcoholics Anonymous, the community that helps...</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-11-07T00:10:00.000Z</td>\n",
       "      <td>Alcoholics Anonymous, the community that helps...</td>\n",
       "      <td>[happiness, step, sorry, volunteers, simple, p...</td>\n",
       "      <td>Which is why a typical individual course for a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Headlines  \\\n",
       "0  Alcoholics Anonymous News and Updates from The...   \n",
       "1                                        Inner Power   \n",
       "2                          Living to see another day   \n",
       "3  Can NREGS become more effective if treated as ...   \n",
       "4                  A simple case of sorry and thanks   \n",
       "\n",
       "                                        Descriptions Authors  \\\n",
       "0  Alcoholics Anonymous News and Updates from The...    None   \n",
       "1  The agnostics say they cant suddenly start bel...    None   \n",
       "2  What's so great about living for the day? Or f...    None   \n",
       "3  A school of thought has emerged that believes ...    None   \n",
       "4  Alcoholics Anonymous, the community that helps...    None   \n",
       "\n",
       "            Published_Dates  \\\n",
       "0                      None   \n",
       "1  2014-06-17T05:50:00.000Z   \n",
       "2  2010-07-23T06:14:00.000Z   \n",
       "3  2010-04-05T11:34:00.000Z   \n",
       "4  2006-11-07T00:10:00.000Z   \n",
       "\n",
       "                                            Articles  \\\n",
       "0  Food ministry seeks delay in ethanol blending ...   \n",
       "1  In a head-to-head evaluation of the Alcoholics...   \n",
       "2  What's so great about living for the day? Or f...   \n",
       "3  Can Alcoholics Anonymous (AA) be turned into a...   \n",
       "4  Alcoholics Anonymous, the community that helps...   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  [mills, food, ministry, business, economic, re...   \n",
       "1  [power, say, step, aa, believe, alcoholics, be...   \n",
       "2  [means, passes, live, moment, day, tomorrow, l...   \n",
       "3  [maximise, nregs, effective, business, yunus, ...   \n",
       "4  [happiness, step, sorry, volunteers, simple, p...   \n",
       "\n",
       "                                           Summaries  \n",
       "0  Food ministry seeks delay in ethanol blending ...  \n",
       "1  In a head-to-head evaluation of the Alcoholics...  \n",
       "2  What's so great about living for the day?\\nThe...  \n",
       "3  Can Alcoholics Anonymous (AA) be turned into a...  \n",
       "4  Which is why a typical individual course for a...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl = pd.DataFrame({'Headlines' : headlines,\n",
    "                    'Descriptions' : descriptions,\n",
    "                    'Authors' : authors,\n",
    "                    'Published_Dates' : dates, \n",
    "                    'Articles' : news,\n",
    "                    'Keywords' : keywords,\n",
    "                    'Summaries' : summaries,})\n",
    "\n",
    "tbl.dropna()\n",
    "tbl.to_csv('The_Economic_Times.csv', index=False)\n",
    "tbl.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
